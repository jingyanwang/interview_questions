{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84fd398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run configuration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce627c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3a2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class churn_model:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim = 128,\n",
    "        dropout_rate = 0.1,\n",
    "        units = 256,\n",
    "        ):\n",
    "        self.emb_dim = emb_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.units = units\n",
    "        self.model = None\n",
    "    \n",
    "    def build_model(\n",
    "        self,\n",
    "        ):\n",
    "        \n",
    "        ###\n",
    "        \n",
    "        input_layers = {}\n",
    "\n",
    "        for c in feature_attributes:\n",
    "            if c in even_attributes:\n",
    "                input_layer = layers.Input(shape = (event_seq_len_max,), name = c)\n",
    "            else:\n",
    "                input_layer = layers.Input(shape = (1,), name = c)\n",
    "            input_layers[c] = input_layer\n",
    "        \n",
    "        ##\n",
    "            \n",
    "        embeddding_layers = {}\n",
    "\n",
    "        for c in attribute_vacabulary_size:\n",
    "            emb_layer = layers.Embedding(\n",
    "                input_dim = attribute_vacabulary_size[c],\n",
    "                output_dim = self.emb_dim,\n",
    "                )(input_layers[c])\n",
    "            embeddding_layers[c] = emb_layer\n",
    "            \n",
    "        ## even sequence laeyrs\n",
    "            \n",
    "        concate_list = [\n",
    "            embeddding_layers[c] if c in embeddding_layers\n",
    "            else layers.Reshape(target_shape = (event_seq_len_max,1))(input_layers[c])\n",
    "            for c in even_attributes\n",
    "        ]\n",
    "\n",
    "        event_seqence_layer = layers.Concatenate()(concate_list)\n",
    "        event_seqence_layer = layers.BatchNormalization()(event_seqence_layer)\n",
    "        event_seqence_layer = layers.Dropout(self.dropout_rate)(event_seqence_layer)\n",
    "\n",
    "        event_seqence_layer = layers.Conv1D(\n",
    "            filters = self.units,\n",
    "            kernel_size = 1,\n",
    "            strides=1,\n",
    "            )(event_seqence_layer)\n",
    "        event_seqence_layer = layers.Dropout(self.dropout_rate)(event_seqence_layer)\n",
    "        event_seqence_layer = layers.GlobalAveragePooling1D()(event_seqence_layer)\n",
    "        \n",
    "        ## profile layers\n",
    "        profile_feature_layers = [\n",
    "            layers.Reshape(target_shape = (self.emb_dim,))(embeddding_layers[c])\n",
    "            for c in feature_attributes\n",
    "            if c in profile_attributes\n",
    "        ]\n",
    "        \n",
    "        ## output layers\n",
    "        feature_layer = layers.Concatenate()(\n",
    "            profile_feature_layers+[event_seqence_layer]\n",
    "            )\n",
    "\n",
    "        feature_layer = layers.Dropout(self.dropout_rate)(feature_layer)\n",
    "        feature_layer = layers.Dense(\n",
    "            units = self.units,\n",
    "            activation = 'relu',\n",
    "            )(feature_layer)\n",
    "        feature_layer = layers.Dropout(self.dropout_rate)(feature_layer)\n",
    "        feature_layer = layers.Dense(\n",
    "            units = self.units,\n",
    "            activation = 'relu',\n",
    "            )(feature_layer)\n",
    "        feature_layer = layers.Dropout(self.dropout_rate)(feature_layer)\n",
    "        output_layer = layers.Dense(\n",
    "            units = 2,\n",
    "            activation = 'softmax',\n",
    "            )(feature_layer)\n",
    "        \n",
    "        ## model\n",
    "        self.model = Model(\n",
    "            inputs = [input_layers[c] for c in input_layers],\n",
    "            outputs = output_layer\n",
    "            )\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=\"adadelta\",\n",
    "            loss= tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.AUC(),\n",
    "                tf.keras.metrics.CategoricalAccuracy(name = 'acc'),\n",
    "                ],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf7366",
   "metadata": {},
   "source": [
    "model = churn_model()\n",
    "model.build_model()\n",
    "\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee251c5",
   "metadata": {},
   "source": [
    "input_layers = {}\n",
    "\n",
    "for c in feature_attributes:\n",
    "    if c in even_attributes:\n",
    "        input_layer = layers.Input(shape = (event_seq_len_max,), name = c)\n",
    "    else:\n",
    "        input_layer = layers.Input(shape = (1,), name = c)\n",
    "    input_layers[c] = input_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6d2b1",
   "metadata": {},
   "source": [
    "embeddding_layers = {}\n",
    "\n",
    "for c in attribute_vacabulary_size:\n",
    "    emb_layer = layers.Embedding(\n",
    "        input_dim = attribute_vacabulary_size[c],\n",
    "        output_dim = emb_dim,\n",
    "        )(input_layers[c])\n",
    "    embeddding_layers[c] = emb_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd061fa",
   "metadata": {},
   "source": [
    "# event sequence feature layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce001399",
   "metadata": {},
   "source": [
    "concate_list = [\n",
    "    embeddding_layers[c] if c in embeddding_layers\n",
    "    else layers.Reshape(target_shape = (event_seq_len_max,1))(input_layers[c])\n",
    "    for c in even_attributes\n",
    "]\n",
    "\n",
    "event_seqence_layer = layers.Concatenate()(concate_list)\n",
    "event_seqence_layer = layers.BatchNormalization()(event_seqence_layer)\n",
    "event_seqence_layer = layers.Dropout(dropout_rate)(event_seqence_layer)\n",
    "\n",
    "event_seqence_layer = layers.Conv1D(\n",
    "    filters = 512,\n",
    "    kernel_size = 1,\n",
    "    strides=1,\n",
    "    )(event_seqence_layer)\n",
    "event_seqence_layer = layers.Dropout(dropout_rate)(event_seqence_layer)\n",
    "event_seqence_layer = layers.GlobalAveragePooling1D()(event_seqence_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602d657",
   "metadata": {},
   "source": [
    "event_seqence_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabd588",
   "metadata": {},
   "source": [
    "# profile layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8d291",
   "metadata": {},
   "source": [
    "profile_feature_layers = [\n",
    "    layers.Reshape(target_shape = (emb_dim,))(embeddding_layers[c])\n",
    "    for c in feature_attributes\n",
    "    if c in profile_attributes\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b73ddd",
   "metadata": {},
   "source": [
    "# output laeyr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec33338",
   "metadata": {},
   "source": [
    "feature_layer = layers.Concatenate()(\n",
    "    profile_feature_layers+[event_seqence_layer]\n",
    "    )\n",
    "\n",
    "feature_layer = layers.Dropout(dropout_rate)(feature_layer)\n",
    "feature_layer = layers.Dense(\n",
    "    units = 512,\n",
    "    activation = 'relu',\n",
    "    )(feature_layer)\n",
    "feature_layer = layers.Dropout(dropout_rate)(feature_layer)\n",
    "feature_layer = layers.Dense(\n",
    "    units = 512,\n",
    "    activation = 'relu',\n",
    "    )(feature_layer)\n",
    "feature_layer = layers.Dropout(dropout_rate)(feature_layer)\n",
    "output_layer = layers.Dense(\n",
    "    units = 2,\n",
    "    activation = 'softmax',\n",
    "    )(feature_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a6b37",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a6fd40",
   "metadata": {},
   "source": [
    "model = Model(\n",
    "    inputs = [input_layers[c] for c in input_layers],\n",
    "    outputs = output_layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46960a4",
   "metadata": {},
   "source": [
    "model.compile(\n",
    "    optimizer=\"adadelta\",\n",
    "    loss='bianry_crossentrory',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.Accuracy(),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766596bf",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
